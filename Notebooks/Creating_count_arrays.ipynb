{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840eb52b-211f-4112-b945-a899a15faa79",
   "metadata": {},
   "source": [
    "# Creating count arrays.\n",
    "\n",
    "**Timing: 1 hour**\n",
    "\n",
    "Before the analysis of translation limitation can begin the data from the ribosome profiling experiments must be organized into count arrays. Count arrays are basically lists that record the number of reads which map to each base pair or codon position along a transcript. The count arrays will be created inside of a Jupyter notebook which is running inside of the Plastid Conda environment set up in the Plastid and Python environment preparations section. Using Plastid to create the count arrays will allow for important adjustments to be made to the data such as applying the p-site offsets made in the Determining p-site offsets section and sub-setting the data to only look at the coding regions of the transcripts. The count arrays will be saved as simple csv tables which can be easily incorporated into further analyses in later sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65db62d-98ad-4240-85e7-5729a1f7364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Python_scripts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7eb9e-7fbf-4321-86a6-0002e11aebe9",
   "metadata": {},
   "source": [
    "## Step 19\n",
    "Load in the python libraries and functions necessary for this pipeline. This includes several functions from plastid and the contents of our utilities.py file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b85093-1e3b-46c2-a5e0-885d8aa26e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plastid import BAMGenomeArray, GTF2_TranscriptAssembler, Transcript\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plastid.plotting.plots import *\n",
    "import utilities as utils\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd607831-dec8-451c-9e48-23e05c8d9f24",
   "metadata": {},
   "source": [
    "## Step 20\n",
    "Load in the table of P-site offsets created in the Determining p-site offsets section using the Pandas function read_csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41737fb-df56-4f2f-a7a7-131bbf7b9d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the P-site offsets for condition 1\n",
    "p_offsets_cond1 = pd.read_csv(\"../Datasets/testing_Psite_offsets/condition1_RPF_1_Aligned.toTranscriptome.out_p-site-offsets\", sep=\"\\t\")\n",
    "\n",
    "# Load in the P-site offsets for condition 2\n",
    "p_offsets_cond2 = pd.read_csv(\"../Datasets/testing_Psite_offsets/condition2_RPF_1_Aligned.toTranscriptome.out_p-site-offsets\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c0ac5d-722d-4abe-ba7b-d7f532e91683",
   "metadata": {},
   "source": [
    "## Step 21\n",
    "Load in a GTF genome annotation file into python using Plastid’s GTF2_TranscriptAssembler function. This function will load in the transcripts as an iterator of Plastid’s transcript type objects which we will then convert to a list using Python’s list function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b265d7-cbe7-476f-89fc-fbbc2f814b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the transcript information\n",
    "transcripts = list(GTF2_TranscriptAssembler(open(\"../Datasets/reference_files/annotation.gtf\"), return_type=Transcript))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff77f24-e46c-46a5-8850-224832dfce03",
   "metadata": {},
   "source": [
    "## Step 22\n",
    "Load in the Bam file containing the Ribosome Profiling data as a Bam Genome Array using Plastid’s BamGenomeArray() function and map the reads to their corresponding P-sites via the VariableThreePrimeMapFactory custom function in utilities.py and Plastid’s set_mapping function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f18008df-fc9f-4fa3-8b33-6f756130ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the alignments from both the condition 1 and condition 2 datasets\n",
    "alignments_cond1 = BAMGenomeArray(\"../Datasets/testing_genome_alignments/condition1_RPF_1_Aligned.sortedByCoord.out.bam\")\n",
    "alignments_cond2 = BAMGenomeArray(\"../Datasets/testing_genome_alignments/condition2_RPF_1_Aligned.sortedByCoord.out.bam\")\n",
    "\n",
    "\"/home/keeganfl/Desktop/Work_Fall_2021/Protocol_test/seleno_seq/\"\n",
    "# Set the P-site offset mappings for both datasets\n",
    "alignments_cond1.set_mapping(utils.VariableThreePrimeMapFactory(p_offsets = p_offsets_cond1))\n",
    "alignments_cond2.set_mapping(utils.VariableThreePrimeMapFactory(p_offsets = p_offsets_cond2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82717d4c-e0ef-4411-b6ba-88d560a8e9e6",
   "metadata": {},
   "source": [
    "## Step 23\n",
    "For each transcript object in our list use Plastid’s get_counts function to create a numpy array that contains the number of counts at each position in the transcript:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdf89fee-023d-4f41-bbab-bc615cadace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize two lists to contain the count arrays\n",
    "count_arrays_cond1 = []\n",
    "count_arrays_cond2 = []\n",
    "\n",
    "# Iterate through each transcript in the GTF file and extract the count arrays for that transcript from the alignments.\n",
    "for transcript in transcripts:\n",
    "    count_arrays_cond1.append(\n",
    "      transcript.get_counts(alignments_cond1))\n",
    "    count_arrays_cond2.append(\n",
    "      transcript.get_counts(alignments_cond2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daa37bd-b53f-4b99-aa1e-8e1c4bfee514",
   "metadata": {},
   "source": [
    "## Step 24\n",
    "Once the count arrays have been created the information on CDS regions contained in the transcript type objects can be used to alter the count arrays to only cover the CDS regions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e916a804-8de5-45e9-aa13-389150adbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize two lists which will contain the start and end positions of the CDS region of each transcript. \n",
    "cds_starts = []\n",
    "cds_ends = []\n",
    "\n",
    "# Iterate through each transcript and add the cds information to the lists\n",
    "for transcript in transcripts:\n",
    "    cds_starts.append(transcript.cds_start)\n",
    "    cds_ends.append(transcript.cds_end)\n",
    "\n",
    "# subset each count array to only look at the cds region. \n",
    "for i in range(len(count_arrays_cond1)):\n",
    "    count_arrays_cond1[i] = list(count_arrays_cond1[i][cds_starts[i]:cds_ends[i]])\n",
    "    count_arrays_cond2[i] = list(count_arrays_cond2[i][cds_starts[i]:cds_ends[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330da1f4-f958-4d23-86cc-1c3d0e52745a",
   "metadata": {},
   "source": [
    "## Step 25\n",
    "Use the add_gene_ids function from utilities.py to append the transcript ID and gene ID of each transcript to the start of the count array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "568e08f8-a28a-419b-ab1e-8dba6add7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.add_gene_ids(transcripts, count_arrays_cond1)\n",
    "utils.add_gene_ids(transcripts, count_arrays_cond2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910edbc-9c3f-4f09-b03f-3a98efba6e9a",
   "metadata": {},
   "source": [
    "## Step 26\n",
    "Filter out any count arrays that are of insufficient length or have insufficient read density. In this example, count arrays which were under 200 base pairs in length or which had a read density cut-off below 0.15 reads per base pair were filtered out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "313eec84-c829-442a-931f-94f946c138d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize two lists to hold the filtered arrays\n",
    "filtered_array_cond1 = []\n",
    "filtered_array_cond2 = []\n",
    "\n",
    "# Iterate through each of the count arrays and save any count arrays that pass our filtering parameters\n",
    "for array_1, array_2 in zip(count_arrays_cond1, count_arrays_cond2):\n",
    "     if len(array_1) > 200 and sum(array_1 [2:])/len(array_1 [2:]) > 0.15 and sum(array_2 [2:])/len(array_2 [2:]) > 0.15:\n",
    "            filtered_array_cond1.append(array_1)\n",
    "            filtered_array_cond2.append(array_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8a6d99-030b-43ff-a939-d57eec96983e",
   "metadata": {},
   "source": [
    "## Step 27\n",
    "Save the count arrays to be used in future notebooks. Use the custom save_count_positions function from utilities.py so that the count arrays are saved with a header that describes each column which it is easier to read. Troubleshooting 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2818a3d-3d5a-42f2-9433-1be12b93f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_count_positions(filtered_array_cond1, \"../Datasets/testing_count_arrays/condition1_1_counts.csv\")\n",
    "utils.save_count_positions(filtered_array_cond2, \"../Datasets/testing_count_arrays/condition2_1_counts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80503ce6-cb39-49c6-9546-1948fe46d3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
